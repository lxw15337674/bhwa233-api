import OpenAI from 'openai';
import { Injectable, BadRequestException, Logger } from '@nestjs/common';
import { AIRequest } from './type';
import { MessageDto } from './dto/summarize.dto';
import puppeteer from 'puppeteer-core';
import chromium from '@sparticuz/chromium';
import MarkdownIt from 'markdown-it';
import { summaryTemplate } from './templates/summary.template';
import { existsSync } from 'fs';
import { join } from 'path';

const aiPrompt = process.env.AI_PROMPT ?? '';

type ToolExecutor = (toolName: string, args: unknown) => Promise<string>;

interface ToolingOptions {
    tools: OpenAI.ChatCompletionTool[];
    executeTool: ToolExecutor;
    toolChoice?: OpenAI.ChatCompletionToolChoiceOption;
    maxToolRounds?: number;
}

@Injectable()
export class AiService {
    private readonly logger = new Logger(AiService.name);
    private openai: OpenAI;

    constructor() {
        this.openai = new OpenAI({
            baseURL: process.env.AI_BASE_URL,
            apiKey: process.env.AI_API_KEY,
        });
    }

    // æ£€æµ‹æœ¬åœ° Chrome è·¯å¾„ï¼ˆWindowsï¼‰
    private findLocalChrome(): string | null {
        const possiblePaths = [
            process.env.CHROME_PATH,
            join(process.env.PROGRAMFILES || 'C:\\Program Files', 'Google\\Chrome\\Application\\chrome.exe'),
            join(process.env['PROGRAMFILES(X86)'] || 'C:\\Program Files (x86)', 'Google\\Chrome\\Application\\chrome.exe'),
            join(process.env.LOCALAPPDATA || '', 'Google\\Chrome\\Application\\chrome.exe'),
        ];

        for (const path of possiblePaths) {
            if (path && existsSync(path)) {
                this.logger.log(`Found Chrome at: ${path}`);
                return path;
            }
        }

        return null;
    }

    async generateResponse(
        body: AIRequest
    ): Promise<string> {
        const {
            prompt,
            model = process.env.AI_MODEL ?? 'step-3',
            rolePrompt = aiPrompt,
            searchDescription = 'å½“éœ€è¦è·å–å®æ—¶ä¿¡æ¯ã€æœ€æ–°æ–°é—»ã€å½“å‰äº‹ä»¶æˆ–ç”¨æˆ·è¯¢é—®çš„ä¿¡æ¯å¯èƒ½éœ€è¦æœ€æ–°æ•°æ®æ—¶ä½¿ç”¨ç½‘ç»œæœç´¢',
            enableWebSearch = false // æ–°å¢å¼€å…³ï¼Œé»˜è®¤ä¸º false
        } = body;

        // éªŒè¯ prompt æ˜¯å¦ä¸ºç©º
        if (!prompt || prompt.trim() === '') {
            this.logger.error('[AI Service] Empty prompt provided:', { prompt, type: typeof prompt });
            throw new BadRequestException('Prompt cannot be empty');
        }

        // ç¡®ä¿ rolePrompt ä¸ä¸ºç©º
        const systemPrompt = rolePrompt.trim() ??'ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚';
        const userPrompt = prompt.trim();

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        const messages = [
            {
                role: "system" as const,
                content: systemPrompt
            },
            {
                role: "user" as const,
                content: userPrompt
            }
        ];

        // æ„å»ºè¯·æ±‚å‚æ•°
        const requestParams: any = {
            messages,
            model,
            ...(enableWebSearch && {
                tool_choice: "auto",
                tools: [
                    {
                        type: "web_search",
                        function: {
                            description: searchDescription
                        }
                    }
                ]
            })
        };
        try {
            const completion = await this.openai.chat.completions.create(requestParams);
            console.log(completion.choices[0].message);
            return completion.choices[0].message.content ?? '';
        } catch (error) {
            this.logger.error('[AI Service] Error generating AI response:', error);
            return 'è·å–AIå›ç­”å¤±è´¥';
        }
    }

    private safeParseToolArgs(rawArgs: string | undefined): Record<string, unknown> {
        if (!rawArgs) {
            return {};
        }
        try {
            const parsed = JSON.parse(rawArgs);
            if (parsed && typeof parsed === 'object') {
                return parsed as Record<string, unknown>;
            }
        } catch (error) {
            this.logger.warn('[AI Service] Failed to parse tool args', error);
        }
        return {};
    }

    async generateResponseWithTools(
        body: AIRequest,
        tooling: ToolingOptions
    ): Promise<string> {
        const {
            prompt,
            model = process.env.AI_MODEL ?? 'step-3',
            rolePrompt = aiPrompt,
        } = body;

        if (!prompt || prompt.trim() === '') {
            this.logger.error('[AI Service] Empty prompt provided:', { prompt, type: typeof prompt });
            throw new BadRequestException('Prompt cannot be empty');
        }

        const systemPrompt = rolePrompt.trim() ?? 'ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚';
        const userPrompt = prompt.trim();

        const messages: OpenAI.ChatCompletionMessageParam[] = [
            {
                role: 'system',
                content: systemPrompt,
            },
            {
                role: 'user',
                content: userPrompt,
            },
        ];

        const maxRounds = tooling.maxToolRounds ?? 3;
        let lastToolResult = '';

        for (let round = 0; round < maxRounds; round += 1) {
            const completion = await this.openai.chat.completions.create({
                messages,
                model,
                tools: tooling.tools,
                tool_choice: tooling.toolChoice ?? 'auto',
            });

            const message = completion.choices[0]?.message;
            if (!message) {
                return lastToolResult || '';
            }

            if (!message.tool_calls || message.tool_calls.length === 0) {
                return message.content ?? '';
            }

            messages.push(message as OpenAI.ChatCompletionMessageParam);

            for (const toolCall of message.tool_calls) {
                const toolName = toolCall.function?.name;
                if (!toolName) {
                    continue;
                }
                const args = this.safeParseToolArgs(toolCall.function.arguments);
                try {
                    const toolResult = await tooling.executeTool(toolName, args);
                    lastToolResult = toolResult;
                    messages.push({
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        content: toolResult,
                    });
                } catch (error) {
                    this.logger.error('[AI Service] Tool execution failed:', error);
                    messages.push({
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        content: 'å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
                    });
                }
            }
        }

        return lastToolResult || 'æœªèƒ½ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼Œè¯·ç¨åé‡è¯•ã€‚';
    }

    // AI æ€»ç»“èŠå¤©è®°å½•
    async summarizeChatMessages(messages: MessageDto[], selfName?: string, groupName?: string): Promise<string> {
        // è¿‡æ»¤æ¶ˆæ¯å¹¶æ ¼å¼åŒ–
        const formatted = messages
            .filter(m => !selfName || m.sender !== selfName)
            .map(m => `[${m.timestamp}] ${m.sender}: ${m.content}`);

        const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŠå¤©è®°å½•æ€»ç»“åŠ©æ‰‹ã€‚è¯·åˆ†æèŠå¤©è®°å½•å¹¶è¾“å‡ºï¼š

## ğŸ“‹ æ¦‚è§ˆ
ç®€è¦æè¿°æœ¬æ¬¡èŠå¤©çš„ä¸»è¦å†…å®¹ï¼ˆ2-3 å¥è¯ï¼‰

## ğŸ’¬ ä¸»è¦è¯é¢˜
- è¯é¢˜1
- è¯é¢˜2
- è¯é¢˜3

## ğŸ“ å¾…åŠäº‹é¡¹
- [ ] å¾…åŠ1
- [ ] å¾…åŠ2

è¦æ±‚ï¼š
1. è¾“å‡º Markdown æ ¼å¼
2. ç®€æ´ä¸“ä¸š
3. ä¸­æ–‡è¾“å‡º`;

        const chatContent = formatted.join('\n');
        const prompt = groupName
            ? `ç¾¤åï¼š${groupName}\n\nèŠå¤©è®°å½•ï¼š\n${chatContent}`
            : `èŠå¤©è®°å½•ï¼š\n${chatContent}`;

        return await this.generateResponse({
            prompt,
            rolePrompt: systemPrompt,
            model: process.env.AI_MODEL ?? 'step-3'
        });
    }

    // ç”Ÿæˆæ€»ç»“å›¾ç‰‡
    async generateSummaryImage(
        messages: MessageDto[],
        selfName?: string,
        groupName?: string,
        includeRanking: boolean = true
    ): Promise<Buffer> {
        // 1. è¿‡æ»¤æ¶ˆæ¯ + ç»Ÿè®¡å‘è¨€æ•°ï¼ˆå†…è”ï¼‰
        const stats = new Map<string, number>();
        messages
            .filter(m => !selfName || m.sender !== selfName)
            .forEach(m => stats.set(m.sender, (stats.get(m.sender) || 0) + 1));

        // 2. AI æ€»ç»“
        const summary = await this.summarizeChatMessages(messages, selfName, groupName);

        // 3. Markdown è½¬ HTMLï¼ˆç®€åŒ–å†…è”ï¼‰
        const md = new MarkdownIt();
        const contentHTML = summary
            .split(/(?=##\s)/)
            .filter(s => s.trim())
            .map(s => `<div class="section">${md.render(s)}</div>`)
            .join('');

        // 4. ç”Ÿæˆæ’è¡Œæ¦œ HTMLï¼ˆå†…è”ï¼‰
        let rankingHTML = '';
        if (includeRanking) {
            const rankingItems = Array.from(stats.entries())
                .sort((a, b) => b[1] - a[1])
                .slice(0, 10)
                .map((entry, i) => {
                    const rankClass = i === 0 ? 'top-1' : i === 1 ? 'top-2' : i === 2 ? 'top-3' : '';
                    return `
                        <div class="ranking-item">
                            <div class="rank-number ${rankClass}">${i + 1}</div>
                            <div class="rank-info">
                                <span class="rank-name">${entry[0]}</span>
                                <span class="rank-count">${entry[1]} æ¡æ¶ˆæ¯</span>
                            </div>
                        </div>
                    `;
                })
                .join('');

            rankingHTML = `
                <div class="section">
                    <h2>ğŸ† å‘è¨€æ’è¡Œæ¦œ</h2>
                    ${rankingItems}
                </div>
            `;
        }

        // 5. ç”Ÿæˆå®Œæ•´ HTML
        const title = groupName ? `${groupName} èŠå¤©æ€»ç»“` : 'èŠå¤©æ€»ç»“';
        const html = summaryTemplate(title, contentHTML, rankingHTML);

        // 6. è·å– Chrome è·¯å¾„
        const isProduction = process.env.NODE_ENV === 'production' || process.env.VERCEL === '1';
        const executablePath = isProduction
            ? await chromium.executablePath()
            : (() => {
                const localChrome = this.findLocalChrome();
                if (!localChrome) {
                    throw new Error('æ— æ³•æ‰¾åˆ°æœ¬åœ° Chrome å®‰è£…ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ CHROME_PATH æˆ–å®‰è£… Google Chrome');
                }
                return localChrome;
            })();

        // 7. Puppeteer æ¸²æŸ“ï¼ˆä¼˜åŒ–ç­‰å¾…ç­–ç•¥ï¼‰
        const browser = await puppeteer.launch({
            args: isProduction ? chromium.args : ['--no-sandbox', '--disable-setuid-sandbox'],
            defaultViewport: {
                width: 600,
                height: 100,
            },
            executablePath,
            headless: true,
        });

        try {
            const page = await browser.newPage();
            await page.setContent(html, { waitUntil: 'networkidle0' }); // ç­‰å¾…å­—ä½“åŠ è½½å®Œæˆ

            const screenshot = await page.screenshot({
                type: 'jpeg',
                quality: 85,
                fullPage: true,
            });

            return screenshot as Buffer;
        } finally {
            await browser.close();
        }
    }
}
