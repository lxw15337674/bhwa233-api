import OpenAI from 'openai';
import { Injectable, BadRequestException, Logger } from '@nestjs/common';
import { AIRequest } from './type';
import { MessageDto } from './dto/summarize.dto';
import puppeteer from 'puppeteer-core';
import chromium from '@sparticuz/chromium';
import { marked } from 'marked';
import { summaryTemplate } from './templates/summary.template';
import { existsSync } from 'fs';
import { join } from 'path';

const aiPrompt = process.env.AI_PROMPT ?? '';

@Injectable()
export class AiService {
    private readonly logger = new Logger(AiService.name);
    private openai: OpenAI;

    constructor() {
        this.openai = new OpenAI({
            baseURL: process.env.AI_BASE_URL,
            apiKey: process.env.AI_API_KEY,
        });
    }

    // æ£€æµ‹æœ¬åœ° Chrome è·¯å¾„ï¼ˆWindowsï¼‰
    private findLocalChrome(): string | null {
        const possiblePaths = [
            process.env.CHROME_PATH,
            join(process.env.PROGRAMFILES || 'C:\\Program Files', 'Google\\Chrome\\Application\\chrome.exe'),
            join(process.env['PROGRAMFILES(X86)'] || 'C:\\Program Files (x86)', 'Google\\Chrome\\Application\\chrome.exe'),
            join(process.env.LOCALAPPDATA || '', 'Google\\Chrome\\Application\\chrome.exe'),
        ];

        for (const path of possiblePaths) {
            if (path && existsSync(path)) {
                this.logger.log(`Found Chrome at: ${path}`);
                return path;
            }
        }

        return null;
    }

    async generateResponse(
        body: AIRequest
    ): Promise<string> {
        const {
            prompt,
            model = process.env.AI_MODEL ?? 'step-3',
            rolePrompt = aiPrompt,
            searchDescription = 'å½“éœ€è¦è·å–å®æ—¶ä¿¡æ¯ã€æœ€æ–°æ–°é—»ã€å½“å‰äº‹ä»¶æˆ–ç”¨æˆ·è¯¢é—®çš„ä¿¡æ¯å¯èƒ½éœ€è¦æœ€æ–°æ•°æ®æ—¶ä½¿ç”¨ç½‘ç»œæœç´¢',
            enableWebSearch = false // æ–°å¢å¼€å…³ï¼Œé»˜è®¤ä¸º false
        } = body;

        // éªŒè¯ prompt æ˜¯å¦ä¸ºç©º
        if (!prompt || prompt.trim() === '') {
            this.logger.error('[AI Service] Empty prompt provided:', { prompt, type: typeof prompt });
            throw new BadRequestException('Prompt cannot be empty');
        }

        // ç¡®ä¿ rolePrompt ä¸ä¸ºç©º
        const systemPrompt = rolePrompt.trim() ??'ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚';
        const userPrompt = prompt.trim();

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        const messages = [
            {
                role: "system" as const,
                content: systemPrompt
            },
            {
                role: "user" as const,
                content: userPrompt
            }
        ];

        // æ„å»ºè¯·æ±‚å‚æ•°
        const requestParams: any = {
            messages,
            model,
            ...(enableWebSearch && {
                tool_choice: "auto",
                tools: [
                    {
                        type: "web_search",
                        function: {
                            description: searchDescription
                        }
                    }
                ]
            })
        };
        try {
            const completion = await this.openai.chat.completions.create(requestParams);
            console.log(completion.choices[0].message);
            return completion.choices[0].message.content ?? '';
        } catch (error) {
            this.logger.error('[AI Service] Error generating AI response:', error);
            return 'è·å–AIå›ç­”å¤±è´¥';
        }
    }

    // æ•°æ®é¢„å¤„ç†
    private preprocessMessages(messages: MessageDto[], selfName?: string): { formatted: string[], stats: Map<string, number> } {
        const stats = new Map<string, number>();
        const formatted = messages
            .filter(m => !selfName || m.sender !== selfName)
            .map(m => {
                stats.set(m.sender, (stats.get(m.sender) || 0) + 1);
                return `[${m.timestamp}] ${m.sender}: ${m.content}`;
            });

        return { formatted, stats };
    }

    // ç”Ÿæˆæ’è¡Œæ¦œï¼ˆHTML æ ¼å¼ï¼‰
    private generateRankingHTML(stats: Map<string, number>): string {
        const entries = Array.from(stats.entries())
            .sort((a, b) => b[1] - a[1])
            .slice(0, 10);

        const rankingItems = entries
            .map((entry, i) => {
                const rankClass = i === 0 ? 'top-1' : i === 1 ? 'top-2' : i === 2 ? 'top-3' : '';
                return `
                    <div class="ranking-item">
                        <div class="rank-number ${rankClass}">${i + 1}</div>
                        <div class="rank-info">
                            <span class="rank-name">${entry[0]}</span>
                            <span class="rank-count">${entry[1]} æ¡æ¶ˆæ¯</span>
                        </div>
                    </div>
                `;
            })
            .join('');

        return `
            <div class="section">
                <h2>ğŸ† å‘è¨€æ’è¡Œæ¦œ</h2>
                ${rankingItems}
            </div>
        `;
    }

    // AI æ€»ç»“èŠå¤©è®°å½•
    async summarizeChatMessages(messages: MessageDto[], selfName?: string, groupName?: string): Promise<string> {
        const { formatted } = this.preprocessMessages(messages, selfName);

        const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŠå¤©è®°å½•æ€»ç»“åŠ©æ‰‹ã€‚è¯·åˆ†æèŠå¤©è®°å½•å¹¶è¾“å‡ºï¼š

## ğŸ“‹ æ¦‚è§ˆ
ç®€è¦æè¿°æœ¬æ¬¡èŠå¤©çš„ä¸»è¦å†…å®¹ï¼ˆ2-3 å¥è¯ï¼‰

## ğŸ’¬ ä¸»è¦è¯é¢˜
- è¯é¢˜1
- è¯é¢˜2
- è¯é¢˜3

## ğŸ“ å¾…åŠäº‹é¡¹
- [ ] å¾…åŠ1
- [ ] å¾…åŠ2

è¦æ±‚ï¼š
1. è¾“å‡º Markdown æ ¼å¼
2. ç®€æ´ä¸“ä¸š
3. ä¸­æ–‡è¾“å‡º`;

        const chatContent = formatted.join('\n');
        const prompt = groupName
            ? `ç¾¤åï¼š${groupName}\n\nèŠå¤©è®°å½•ï¼š\n${chatContent}`
            : `èŠå¤©è®°å½•ï¼š\n${chatContent}`;

        return await this.generateResponse({
            prompt,
            rolePrompt: systemPrompt,
            model: process.env.AI_MODEL ?? 'step-3'
        });
    }

    // å°† Markdown å†…å®¹è½¬ä¸º HTML section
    private markdownToHTMLSections(markdown: string): string {
        // åˆ†å‰² Markdown æŒ‰ h2 æ ‡é¢˜
        const sections = markdown.split(/(?=##\s)/);

        return sections
            .filter(section => section.trim())
            .map(section => {
                const html = marked.parse(section);
                return `<div class="section">${html}</div>`;
            })
            .join('');
    }

    // ç”Ÿæˆæ€»ç»“å›¾ç‰‡
    async generateSummaryImage(
        messages: MessageDto[],
        selfName?: string,
        groupName?: string,
        includeRanking: boolean = true
    ): Promise<Buffer> {
        // æ•°æ®é¢„å¤„ç†
        const { stats } = this.preprocessMessages(messages, selfName);

        // AI æ€»ç»“
        const summary = await this.summarizeChatMessages(messages, selfName, groupName);

        // ç”Ÿæˆæ’è¡Œæ¦œ HTML
        const rankingHTML = includeRanking ? this.generateRankingHTML(stats) : '';

        // å°† Markdown æ€»ç»“è½¬ä¸º HTML
        const contentHTML = this.markdownToHTMLSections(summary);

        // æ ‡é¢˜
        const title = groupName ? `${groupName} èŠå¤©æ€»ç»“` : 'èŠå¤©æ€»ç»“';

        // ç”Ÿæˆå®Œæ•´ HTML
        const html = summaryTemplate(title, contentHTML, rankingHTML);

        // æ£€æµ‹æ˜¯å¦ä¸ºæœ¬åœ°å¼€å‘ç¯å¢ƒ
        const isProduction = process.env.NODE_ENV === 'production' || process.env.VERCEL === '1';

        // è·å– Chrome å¯æ‰§è¡Œè·¯å¾„
        let executablePath: string;
        if (isProduction) {
            executablePath = await chromium.executablePath();
        } else {
            const localChrome = this.findLocalChrome();
            if (!localChrome) {
                throw new Error('æ— æ³•æ‰¾åˆ°æœ¬åœ° Chrome å®‰è£…ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ CHROME_PATH æˆ–å®‰è£… Google Chrome');
            }
            executablePath = localChrome;
        }

        // ä½¿ç”¨ Puppeteer æ¸²æŸ“
        const browser = await puppeteer.launch({
            args: isProduction ? chromium.args : ['--no-sandbox', '--disable-setuid-sandbox'],
            defaultViewport: {
                width: 600,
                height: 100, // æœ€å°é«˜åº¦ï¼Œå®é™…ä¼šæ ¹æ®å†…å®¹è‡ªåŠ¨æ‰©å±•ï¼ˆfullPage: trueï¼‰
            },
            executablePath,
            headless: true,
        });

        try {
            const page = await browser.newPage();
            await page.setContent(html, { waitUntil: 'networkidle0' });

            // æˆªå›¾
            const screenshot = await page.screenshot({
                type: 'png',
                fullPage: true,
            });

            return screenshot as Buffer;
        } finally {
            await browser.close();
        }
    }
}